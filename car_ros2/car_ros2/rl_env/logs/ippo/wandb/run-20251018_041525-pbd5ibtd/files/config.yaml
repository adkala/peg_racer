_wandb:
    value:
        cli_version: 0.21.1
        code_path: code/car_ros2/car_ros2/rl_env/train_ippo.py
        e:
            z5471o9bth5i7q9stjourm4f048wfmv5:
                apple:
                    ecpuCores: 4
                    gpuCores: 7
                    memoryGb: 8
                    name: Apple M1
                    pcpuCores: 4
                    ramTotalBytes: "8589934592"
                    swapTotalBytes: "10737418240"
                codePath: car_ros2/car_ros2/rl_env/train_ippo.py
                codePathLocal: train_ippo.py
                cpu_count: 8
                cpu_count_logical: 8
                disk:
                    /:
                        total: "245107195904"
                        used: "244202471424"
                email: sbharvirkar@berkeley.edu
                executable: /Users/sanikabharvirkar/anaconda3/envs/jaxastar/bin/python3
                git:
                    commit: 9cff4036e6e671821a2d5280af76d3076a5dcbff
                    remote: https://github.com/sastry-group/alpha-RACER.git
                host: Sanikas-MacBook-Air-2.local
                memory:
                    total: "8589934592"
                os: macOS-15.1-arm64-arm-64bit
                program: /Users/sanikabharvirkar/Documents/alpha-RACER/car_ros2/car_ros2/rl_env/train_ippo.py
                python: CPython 3.11.13
                root: ./logs/ippo
                startedAt: "2025-10-18T11:15:25.047213Z"
                writerId: z5471o9bth5i7q9stjourm4f048wfmv5
        m: []
        python_version: 3.11.13
        t:
            "1":
                - 1
                - 12
                - 105
            "2":
                - 1
                - 12
                - 105
            "3":
                - 13
                - 16
                - 34
                - 35
            "4": 3.11.13
            "5": 0.21.1
            "10":
                - 20
            "12": 0.21.1
            "13": darwin-arm64
algo:
    value: PPO
batch_size:
    value: 64
clip_range:
    value: 0.2
gae_lambda:
    value: 0.95
gamma:
    value: 0.99
learning_rate:
    value: 0.0005
n_epochs:
    value: 5
n_steps_effective:
    value: 128
num_envs:
    value: 4
trajectory_type:
    value: ../../../simulators/params-num.yaml
